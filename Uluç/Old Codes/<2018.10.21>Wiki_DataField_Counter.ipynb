{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Article():\n",
    "    def __init__(self,text):\n",
    "        try:\n",
    "            bulk = text.split('#')\n",
    "            if len(bulk) != 6:\n",
    "                self.kill = True\n",
    "            else:\n",
    "                self.kill = False\n",
    "                self.id = bulk[0]\n",
    "                self.title = bulk[1]\n",
    "                self.info_box_type = bulk[2]\n",
    "                self.clean_info_box = self.map_json_keys(json.loads(bulk[3].replace('karakteradı','ad').replace('adı','ad')))\n",
    "                self.bulk_info_box = json.loads(bulk[4])\n",
    "                self.paragraph = bulk[5]\n",
    "                self.filed_counter = Counter(self.clean_info_box)\n",
    "        except Exception as e:\n",
    "            print e\n",
    "            #print e\n",
    "    def map_json_keys(self,d):\n",
    "        # ad\n",
    "        for_name =  ['adı','isim','ismi','adi','name','karakteradı']\n",
    "        for n in for_name:\n",
    "            try : \n",
    "                d['ad']= json.dumps(d[n], ensure_ascii=False, encoding='utf8')\n",
    "                del d[n]\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        return d\n",
    "        '''\n",
    "        \n",
    "        # doğumyeri\n",
    "        for_birth_place = ['doğum_yeri']\n",
    "        # 'resim' varsa sil\n",
    "        '''\n",
    "        \n",
    "def reader(articles_path):\n",
    "    article_text = open(articles_path, \"r\") .read()\n",
    "    articles = []\n",
    "    for a in article_text.split('\\n\\n\\n'):\n",
    "        article = Article(a)\n",
    "        if article.kill == False:\n",
    "            articles.append(article)\n",
    "    return articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_path ='/Users/uluc/Desktop/Bitirme/Wikiparse_WorkSpace/<2018.10.-->Wiki/<2018-10-21>Outputs-ArticleClean/Clean_Interested_Articles.txt'\n",
    "articles = reader(article_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_of_fields = {}\n",
    "\n",
    "for a in articles:\n",
    "    try:\n",
    "        counter_of_fields[a.info_box_type]['count'] += Counter(a.clean_info_box.keys())\n",
    "        counter_of_fields[a.info_box_type]['number'] += 1 \n",
    "    except Exception as e:\n",
    "        counter_of_fields[a.info_box_type] = {}\n",
    "        counter_of_fields[a.info_box_type]['count'] = Counter(a.clean_info_box.keys())\n",
    "        counter_of_fields[a.info_box_type]['number'] = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import os\n",
    "def create_files():\n",
    "    today = date.today().strftime('<%Y-%m-%d>')\n",
    "    mypath = '../'+today+'Outputs-DataFieldCount'\n",
    "    if not os.path.isdir(mypath):\n",
    "        os.makedirs(mypath)\n",
    "    log_path = '../'+today+'Outputs-DataFieldCount/DataFieldCount_Report.txt'\n",
    "    f= open(log_path,\"w\")\n",
    "    \n",
    "    ex_path = '../'+today+'Outputs-DataFieldCount/Counters'\n",
    "    if not os.path.isdir(ex_path):\n",
    "        os.makedirs(ex_path)\n",
    "    uniq_path = '../'+today+'Outputs-DataFieldCount/Uniq'\n",
    "    if not os.path.isdir(uniq_path):\n",
    "        os.makedirs(uniq_path)\n",
    "    return mypath+'/',ex_path+'/',log_path,uniq_path+'/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path, ex_path, log_path,uniq_path = create_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tüm countları bastırma\n",
    "allCounters = Counter()\n",
    "number = 0\n",
    "for i in counter_of_fields.keys():\n",
    "    allCounters +=counter_of_fields[i]['count']\n",
    "    number += counter_of_fields[i]['number']\n",
    "\n",
    "f = open(output_path+'all_count.txt',\"w\")\n",
    "aa = '#Info Box Type : {}, #Total article with infoBox: {}\\n\\n'.format(len(counter_of_fields.keys()),number)\n",
    "a = json.dumps(allCounters.most_common(), ensure_ascii=False, encoding='utf8',indent = 4).encode('utf-8')\n",
    "f.write(aa)\n",
    "f.write(a)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# her bir cat için bastırma counter\n",
    "for i in counter_of_fields.keys():\n",
    "    f = open(ex_path+str(i)+'.txt',\"w\")\n",
    "    aa = 'Info Box Type : {}, #Total article with this infoBox: {}\\n\\n'.format(i,counter_of_fields[i]['number'])\n",
    "    a = json.dumps(counter_of_fields[i]['count'].most_common(), ensure_ascii=False, encoding='utf8',indent = 4).encode('utf-8')\n",
    "    f.write(aa)\n",
    "    f.write(a)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_uniq_fields(all_types,who,uniq_path):\n",
    "    st = 'Uniq Data Fields for {} -------\\n'.format(all_types.keys()[who])\n",
    "    one_type = all_types[all_types.keys()[who]]['count']\n",
    "    other_types = {}\n",
    "    other_types =  [ all_types[k]['count']  for k in all_types.keys() if k != all_types.keys()[who]]\n",
    "    result = []\n",
    "    for element in one_type.keys():\n",
    "        Flag = False\n",
    "        for cs in other_types:\n",
    "            if cs[element] != 0:\n",
    "                Flag=True\n",
    "        if Flag == False:\n",
    "            result.append(element)\n",
    "    #strr = ' \\n'.join(result)\n",
    "    f= open(uniq_path+all_types.keys()[who]+'_Uniq_Fields.txt',\"w\")\n",
    "    f.write(st)\n",
    "    f.write(json.dumps(result, ensure_ascii=False, encoding='utf8',indent = 4).encode('utf-8'))\n",
    "    \n",
    "    \n",
    "for ii in range (0,len(counter_of_fields.keys())):\n",
    "    give_uniq_fields (counter_of_fields,ii,uniq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çıktı göresterme\n",
    "f= open(output_path+'Counts2.txt',\"w\")\n",
    "f.close()\n",
    "for i in counter_of_fields.keys():\n",
    "    f= open(output_path+'Counts2.txt',\"ab\")\n",
    "    a = []\n",
    "    for j in counter_of_fields[i]['count'].most_common(10):\n",
    "        y = counter_of_fields[i]['number']\n",
    "        b = json.dumps(j, ensure_ascii=False, encoding='utf8').\\\n",
    "                    replace(']','').replace('[','')\\\n",
    "                    .replace('\"','').replace(',',':').strip()\n",
    "        bb = int(b.split(':')[1].strip())\n",
    "        a.append( ('%26s|')%( b ))\n",
    "    u = unicode(i, \"utf-8\")\n",
    "    ab = u.rjust(22,' ')+str(counter_of_fields[i]['number']).rjust(6,' ')+' ->'\n",
    "    ab = ab.encode('utf8')\n",
    "    for bb in a:\n",
    "        ab += bb.encode('utf-8')\n",
    "    f.write(ab)\n",
    "    f.write('\\n') \n",
    "    f.close()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çıktı göresterme\n",
    "f= open(output_path+'Counts2.txt',\"ab\")\n",
    "f.write('\\n')\n",
    "for i in counter_of_fields.keys():\n",
    "    a = []\n",
    "    for j in counter_of_fields[i]['count'].most_common(10):\n",
    "        y = counter_of_fields[i]['number']\n",
    "        b = json.dumps(j, ensure_ascii=False, encoding='utf8').\\\n",
    "                    replace(']','').replace('[','')\\\n",
    "                    .replace('\"','').replace(',',':').strip()\n",
    "        bb = int(b.split(':')[1].strip())\n",
    "        a.append( ('%20s: %.2f|')%( b.split(':')[0].strip(),bb/float(y) ))\n",
    "    u = unicode(i, \"utf-8\")\n",
    "    ab = u.rjust(22,' ')+str(counter_of_fields[i]['number']).rjust(6,' ')+' ->'\n",
    "    ab = ab.encode('utf8')\n",
    "    for bb in a:\n",
    "        ab += bb.encode('utf-8')\n",
    "    f.write(ab)\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çıktı göresterme\n",
    "f= open(output_path+'Counts2.txt',\"ab\")\n",
    "f.write('\\n')\n",
    "for i in counter_of_fields.keys():\n",
    "    a = []\n",
    "    for j in counter_of_fields[i]['count'].most_common(10):\n",
    "        y = counter_of_fields[i]['number']\n",
    "        b = json.dumps(j, ensure_ascii=False, encoding='utf8').\\\n",
    "                    replace(']','').replace('[','')\\\n",
    "                    .replace('\"','').replace(',',':').strip()\n",
    "        bb = int(b.split(':')[1].strip())\n",
    "        if bb/float(y)>=0.60:\n",
    "            a.append( ('%20s: %.2f|')%( b.split(':')[0].strip(),bb/float(y) ))\n",
    "        else:\n",
    "            a.append( ('%26s|')%( '' ))\n",
    "    u = unicode(i, \"utf-8\")\n",
    "    ab = u.rjust(22,' ')+str(counter_of_fields[i]['number']).rjust(6,' ')+' ->'\n",
    "    ab = ab.encode('utf8')\n",
    "    for bb in a:\n",
    "        ab += bb.encode('utf-8')\n",
    "    f.write(ab)\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(output_path+'Counts2.txt',\"ab\")    \n",
    "f.write('\\n\\nGenel durum\\n')    \n",
    "total = ('%25s|')%(json.dumps(allCounters.most_common(20), ensure_ascii=False, encoding='utf8').\\\n",
    "                    replace(']','').replace('[','')\\\n",
    "                    .replace('\"','').replace(',',':').strip() )\n",
    "f.write(total.encode('utf-8'))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clean_articles(output_path,articles):\n",
    "    fd= open(output_path+'All_Article.txt',\"w\")\n",
    "    fd.close()\n",
    "    f= open(output_path+'All_Article.txt',\"ab\")\n",
    "    for a in articles:\n",
    "        try:\n",
    "            bd = json.dumps(a.clean_info_box, ensure_ascii=False, encoding='utf8').encode('utf-8')\n",
    "            cd = json.dumps(a.bulk_info_box, ensure_ascii=False, encoding='utf8').encode('utf-8')\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        f.write(str(a.id) +'#')\n",
    "        f.write(str(a.title) +'#')\n",
    "        f.write(str(a.info_box_type) +'#')\n",
    "        f.write(bd)\n",
    "        f.write('#')\n",
    "        f.write(cd)\n",
    "        f.write('#')\n",
    "        f.write(str(a.paragraph)) \n",
    "        f.write('\\n\\n\\n')\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clean_articles(output_path,articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Author = Uluç Furkan Vardar\n",
    " \n",
    " Version = 3.0\n",
    " \n",
    "## Using this code you can manipulate Wiki Dump Extracted data (Depending Interested Data). \n",
    "### The data you will obtain;\n",
    "\n",
    "\n",
    "###### All article that we are interested\n",
    "    * Article id\n",
    "    * Article title\n",
    "    * Article infoBox type\n",
    "    * Article infoBox as bulk\n",
    "    * Article infoBox as clean (empty places thrown or normal)\n",
    "    * The first sentences of the article as clean\n",
    "    * total counts, graphfs\n",
    "    * InfoBox Data Field Counts and examples for every one InfoBox Type \n",
    "    * Also infoBox_Clean DataFiled Counts\n",
    "    * DataField uniqless flag for InfoBox Types\n",
    "    * Also all needed graphs and counts for all \n",
    "\n",
    "\n",
    " \n",
    "---\n",
    "The output of the program is placed in an output folder created for that date. (EX Folder name: <2018-10-07>Output/ )\n",
    "The output consists .txt,.pdf,.png files (Grapfhs data etc.).\n",
    "\n",
    "\n",
    "#### All Article information. \n",
    " \tfile named '<2018-10-07>All_Article.txt'\n",
    " \t(Format: ...\\n\\n\\nArticle_id#Article_title#infoBoxType#infoBox_bulk#infoBox_clean#first_paragraph\\n\\n\\n...)\n",
    " \n",
    "####  Hit counter for every infoBox type.\n",
    " \tfile named '<2018-10-07>infoBoxType_Counter.txt'\n",
    " \t(Format: ...\\ninfoBoxType#hit_counter\\n...)\n",
    " \n",
    "###### Also, A Log file is generated and the important things about the data processing area are printed....\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "#from dataCleaner import DataCleaner as DC\n",
    "\n",
    "\n",
    "class InterestedArticles():\n",
    "    def __init__(self,interested_file_path,all_articles):\n",
    "        self.Interested_InfoBoxes = []\n",
    "        \n",
    "        # Taking info about Interested InfoBoxes        \n",
    "        self.Interested_InfoBoxTypes_text = open(interested_file_path, \"r\") .read()\n",
    "        self.parse_interested_infoBox()\n",
    "        \n",
    "        # Taking info about Articles\n",
    "        self.articles_text  = open(all_articles, \"r\").read() \n",
    "        self.articles_as_list = self.articles_text.split('\\n\\n\\n')\n",
    "        for i in range(0,len(self.articles_as_list)):\n",
    "            self.articles_as_list[i] = self.articles_as_list[i].split('#')\n",
    "            try:\n",
    "                if self.articles_as_list[i][2] not in self.Interested_InfoBoxes:\n",
    "                    self.articles_as_list[i] = None\n",
    "            except Exception as e:\n",
    "                self.articles_as_list[i] = None\n",
    "                continue\n",
    "        self.articles_as_list = [x for x in self.articles_as_list if x is not None]\n",
    "        self.allinterested_number = len(self.articles_as_list)\n",
    "    def save_clean_articles(self,path):\n",
    "        self.canbesaved = 0\n",
    "        fh = codecs.open(path+'Clean_Interested_Articles.txt','ab','utf8')\n",
    "        f = open(path+'Clean_Interested_Articles.txt','ab')\n",
    "        for a in self.articles_as_list:\n",
    "            try:\n",
    "                bd = json.dumps(a[3], ensure_ascii=False, encoding='utf8').encode('utf-8')\n",
    "                cd = json.dumps(a[5], ensure_ascii=False, encoding='utf8').encode('utf-8')\n",
    "            except Exception as e:\n",
    "                continue\n",
    "            #print type(bd)\n",
    "            #print type('#'+str(a[4])+'#')\n",
    "            \n",
    "            f.write(str(a[0]) +'#')\n",
    "            f.write(str(a[1]) +'#')\n",
    "            f.write(str(a[2]) +'#')\n",
    "            f.write(bd)\n",
    "            f.write('#')\n",
    "            f.write(cd)\n",
    "            f.write('#')\n",
    "            f.write(str(a[4])) \n",
    "            f.write('\\n\\n\\n')\n",
    "            self.canbesaved +=1\n",
    "            \n",
    "                    \n",
    "    def parse_interested_infoBox(self):\n",
    "        self.Interested_InfoBoxes = self.Interested_InfoBoxTypes_text.split('\\n')\n",
    "        if len(self.Interested_InfoBoxes[len(self.Interested_InfoBoxes)-1] ) <3:\n",
    "            del self.Interested_InfoBoxes[len(self.Interested_InfoBoxes)-1] \n",
    "        for i in range(0,len(self.Interested_InfoBoxes)):\n",
    "            self.Interested_InfoBoxes[i] = self.Interested_InfoBoxes[i][:self.Interested_InfoBoxes[i].find('#')]\n",
    "\n",
    "    def save_one_example_of_InfoBoxType_clear_and_bulk(self,output_path):\n",
    "        mypath = output_path+'InfoBoxType_Examples'\n",
    "        if not os.path.isdir(mypath):\n",
    "            os.makedirs(mypath)\n",
    "            \n",
    "        templist = [x for x in self.Interested_InfoBoxes]\n",
    "        \n",
    "        for t in self.articles_as_list:\n",
    "            if t[2] in templist:      \n",
    "                try:\n",
    "                    file_path = mypath+'/'+t[2]+'.txt'\n",
    "                    f = codecs.open(file_path,'w','utf8')\n",
    "                    f.write(json.dumps(t[5], ensure_ascii=False, encoding='utf8',indent=4))\n",
    "                    f.write('\\n\\n')\n",
    "                    f.write(json.dumps(t[3], ensure_ascii=False, encoding='utf8',indent=4))      \n",
    "                except Exception as e:\n",
    "                    print e\n",
    "                    continue\n",
    "            templist = [x for x in templist if x is not t[2]]\n",
    "            if len(templist)==0:\n",
    "                break\n",
    "\n",
    "\n",
    "            \n",
    "    def convert_all_articles_2_clean_json(self):\n",
    "        for i in range(0,len(self.articles_as_list)):\n",
    "            try:\n",
    "                self.articles_as_list[i].append( self.convert_2_json(self.articles_as_list[i][3].replace('<nl>','\\n')))\n",
    "                self.articles_as_list[i][3] = self.clean_jsons(self.articles_as_list[i][5])\n",
    "            except Exception as e:\n",
    "                #print e\n",
    "                continue\n",
    "    \n",
    "    def clean_jsons(self,json_text):\n",
    "        new_json = {}\n",
    "        for key in json_text.keys():\n",
    "            temp_key = key\n",
    "            temp_key = temp_key.replace(' ','').replace('-','').replace('_','').lower()\n",
    "            temp_value = json_text[key]\n",
    "            if temp_value.count('|') == 1:\n",
    "                if '[[' in temp_value:\n",
    "                    temp_value = self.clean_values(temp_value)\n",
    "                if '{{' in temp_value:\n",
    "                    temp_value = self.clean_values2(temp_value)\n",
    "            temp_value = temp_value.replace('[[','').replace(']]','')\n",
    "            \n",
    "            # <br\\>\n",
    "            temp_value = temp_value.replace('<br />',', ').replace('<br/>',', ').replace('<br/ >',', ')\\\n",
    "            .replace('<br>',', ').replace('<br >',', ').replace(\"''\",'')\n",
    "            temp_value = self.clean_ref_tag(temp_value)\n",
    "            \n",
    "            if temp_value.count('}}') ==1 and temp_value.count('{{') ==0:\n",
    "                temp_value = temp_value.replace('}}','')\n",
    "            if temp_value.count('{{') ==1 and temp_value.count('}}') ==0:\n",
    "                temp_value = temp_value.replace('{{','')\n",
    "            \n",
    "            if temp_value != \"\" :\n",
    "                if 'imza' in key or 'resim' in key :\n",
    "                    pass\n",
    "                else:\n",
    "                    new_json[temp_key.strip()] = temp_value.strip()\n",
    "            \n",
    "        return new_json\n",
    "              \n",
    "    def convert_2_json(self,text):\n",
    "        lines = text.split('\\n')\n",
    "        temp = {}\n",
    "        for i in range(1,len(lines)):\n",
    "            temp_key = \"\"\n",
    "            temp_value = \"\"\n",
    "            lines[i] = lines[i].strip()\n",
    "            if lines[i].count('=') == 1:\n",
    "                if '|' in lines[i]:\n",
    "                    m = re.search(\".*\\|(.*)=(.*)\",lines[i])\n",
    "                    #print lines[i]\n",
    "                    temp_key = (m.group(1)).replace('|','').strip()\n",
    "                    temp_value = m.group(2).strip()\n",
    "                    temp[temp_key] = temp_value\n",
    "                else:\n",
    "                    #print lines[i],\"-----\"\n",
    "                    #print 'HATA!! PİPE YOK..'\n",
    "                    continue\n",
    "            else:\n",
    "                if '}}' == lines[i]:\n",
    "                    continue\n",
    "                #print lines[i],\"-----\"\n",
    "                #print 'HATA! BİRDEN FAZLA EŞİTTİR/Yok......\\n\\n\\n\\n'\n",
    "                continue  \n",
    "        return temp\n",
    "    def clean_values2(self, sentence):\n",
    "        #print sentence\n",
    "        paragraph = sentence.split('{{')\n",
    "        for i in range(0,len(paragraph)):\n",
    "            try:\n",
    "                paragraph[i] = (re.search(\".*\\|(.*)\\}\\}.*\",paragraph[i])).group(1)+\" \"\n",
    "            except Exception as e:\n",
    "                if i == 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    paragraph[i] = paragraph[i]\n",
    "                pass\n",
    "        return  ''.join(paragraph)\n",
    "    \n",
    "    def clean_values(self, sentence):\n",
    "        #print sentence\n",
    "        paragraph = sentence.split('[[')\n",
    "        for i in range(0,len(paragraph)):\n",
    "            try:\n",
    "                paragraph[i] = '[['+(re.search(\".*\\|(.*\\]\\].*)\",paragraph[i])).group(1)+\" \"\n",
    "            except Exception as e:\n",
    "                if i == 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    paragraph[i] = '[['+paragraph[i]\n",
    "                pass\n",
    "        return  ''.join(paragraph)\n",
    "    def clean_ref_tag(self, paragraph):\n",
    "        \n",
    "        paragraph = paragraph.split('\\n')\n",
    "        \n",
    "        '''\n",
    "            paragraph: it is a sentencering with '\\n'. \n",
    "                    Thus, it's able to be porcessed \n",
    "                    line by line here.\n",
    "        '''\n",
    "        for i,line in enumerate(paragraph):\n",
    "            open_ref = 0\n",
    "            close_ref = 0\n",
    "\n",
    "            # count 'em all in the line\n",
    "            if '<ref' in line:\n",
    "                open_ref = line.count(\"<ref\")\n",
    "            if '</ref>' in line:\n",
    "                close_ref = line.count(\"</ref>\")\n",
    "\n",
    "\n",
    "            # if there are many opened and closed 'ref' tags\n",
    "\n",
    "            # open > close\n",
    "            if open_ref > close_ref:\n",
    "                while(open_ref > 0 and close_ref > 0):\n",
    "                    o_index = line.find('<ref')\n",
    "                    c_index = line.find('</ref>')\n",
    "                    if o_index < c_index:\n",
    "                        firsentence_part = line[:line.find('<ref')]\n",
    "                        second_part = line[line.find('</ref>')+6:]\n",
    "                        paragraph[i] = firsentence_part + second_part\n",
    "                        line = paragraph[i]\n",
    "                        open_ref-=1\n",
    "                        close_ref-=1\n",
    "                o_index = line.find('<ref')\n",
    "                paragraph[i] = line[:line.find('<ref')]\n",
    "\n",
    "            # closed > opened\n",
    "            if close_ref > open_ref:\n",
    "                paragraph[i] = line[line.find('</ref>')+6:]\n",
    "                line = paragraph[i]\n",
    "                close_ref-=1\n",
    "                while(open_ref > 0 and close_ref > 0):\n",
    "                    o_index = line.find('<ref')\n",
    "                    c_index = line.find('</ref>')\n",
    "                    if o_index < c_index:\n",
    "                        firsentence_part = line[:line.find('<ref')]\n",
    "                        second_part = line[line.find('</ref>')+6:]\n",
    "                        paragraph[i] = firsentence_part + second_part\n",
    "                        line = paragraph[i]\n",
    "                        open_ref-=1\n",
    "                        close_ref-=1\n",
    "\n",
    "            # (open = close) and > 1 \n",
    "            if open_ref > 1 and close_ref > 1:\n",
    "                while(open_ref > 1 and close_ref > 1):\n",
    "                    o_index = line.find('<ref')\n",
    "                    c_index = line.find('</ref>')\n",
    "                    if o_index < c_index:\n",
    "                        firsentence_part = line[:line.find('<ref')]\n",
    "                        second_part = line[line.find('</ref>')+6:]\n",
    "                        paragraph[i] = firsentence_part + second_part\n",
    "                        open_ref-=1\n",
    "                        close_ref-=1\n",
    "\n",
    "            # for 1 opened and 1 closed tags\n",
    "            if open_ref == 1 and close_ref == 1:\n",
    "                paragraph[i] = re.sub(r\"<ref(.|\\n)*</ref>\",\"\",paragraph[i])\n",
    "        return '\\n'.join(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_path = '/Users/uluc/Desktop/Bitirme/Wikiparse_WorkSpace/<2018.10.-->Wiki/<2018-10-20>Outputs-InfoBoxClean/Interested_InfoBoxType_Count.txt'\n",
    "all_articles = '/Users/uluc/Desktop/Bitirme/Wikiparse_WorkSpace/<2018.10.-->Wiki/<2018-10-20>Outputs_Bulk/All_Article.txt'\n",
    "\n",
    "intrested = InterestedArticles(interested_path,all_articles)\n",
    "\n",
    "\n",
    "intrested.convert_all_articles_2_clean_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "def create_files():\n",
    "    today = date.today().strftime('<%Y-%m-%d>')\n",
    "    mypath = '../'+today+'Outputs-ArticleClean'\n",
    "    if not os.path.isdir(mypath):\n",
    "        os.makedirs(mypath)\n",
    "    log_path = '../'+today+'Outputs-ArticleClean/ArticleCleaner_Report.txt'\n",
    "    f= open(log_path,\"w\")\n",
    "\n",
    "    '''    \n",
    "    article_path = '../'+today+'Outputs-InfoBoxClean/'+today+'All_Article.txt'\n",
    "    counter_path = '../'+today+'Outputs-InfoBoxClean/'+today+'infoBoxType_Counter.txt'\n",
    "    log_path = '../'+today+'Outputs-InfoBoxClean/'+today+'Extractor Report.txt'\n",
    "    f= open(article_path,\"w\")\n",
    "    f= open(counter_path,\"w\")\n",
    "    f= open(log_path,\"w\")\n",
    "    '''\n",
    "    return mypath+'/',log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "output_path,log_path = create_files()\n",
    "\n",
    "intrested.save_one_example_of_InfoBoxType_clear_and_bulk(output_path = output_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savelog(path,title,text):\n",
    "    with open(path, \"ab\") as myfile:\n",
    "            myfile.write(title +\" ---------\\n\")\n",
    "            myfile.write( text+\"\\n\")\n",
    "            myfile.write(\"--------------------------\\n\\n\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrested.save_clean_articles(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savelog(log_path,'Article Cleaning',(' #Total Interested Article: {}\\n #Total Saved Interested Article: {}\\n'.format(intrested.allinterested_number,intrested.canbesaved)))\n",
    "savelog(log_path,'Operations',' All interested articles are taken\\n All infoboxes convert to to json\\n All info boxes cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

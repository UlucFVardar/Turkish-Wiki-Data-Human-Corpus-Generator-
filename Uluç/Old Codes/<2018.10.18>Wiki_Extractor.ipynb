{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author = Ulu√ß Furkan Vardar\n",
    "\n",
    "Version = 3.0\n",
    "\n",
    "## Using this code you can manipulate Wiki Dump data. \n",
    "##### The data you will obtain;\n",
    "\t* Article id\n",
    "\t* Article title\n",
    "\t* Article infoBox type\n",
    "    * Article infoBox as bulk\n",
    "\t* Article infoBox as clean (empty places thrown or normal)\n",
    "\t* The first paragraph of the article as bulk\n",
    "\n",
    "\n",
    "The output of the program is placed in an output folder created for that date. (EX Folder name: <2018-10-07>Output/ )\n",
    "The output consists of three .txt files.\n",
    "#### All Article information. \n",
    "\tfile named '<2018-10-07>All_Article.txt'\n",
    "\t(Format: ...\\n\\n\\nArticle_id#Article_title#infoBoxType#infoBox_bulk#infoBox_clean#first_paragraph\\n\\n\\n...)\n",
    "\n",
    "####  Hit counter for every infoBox type.\n",
    "\tfile named '<2018-10-07>infoBoxType_Counter.txt'\n",
    "\t(Format: ...\\ninfoBoxType#hit_counter\\n...)\n",
    "\n",
    "###### Also, A Log file is generated and the important things about the data processing area are printed...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stack:\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "\n",
    "    def isEmpty(self):\n",
    "        return self.items == []\n",
    "\n",
    "    def push(self, item):\n",
    "        self.items.append(item)\n",
    "\n",
    "    def pop(self):\n",
    "        return self.items.pop()\n",
    "\n",
    "    def peek(self):\n",
    "        return self.items[len(self.items)-1]\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "class WikiDumpParser:\n",
    "    def __init__(self,file_path):\n",
    "        self.error_count = 0\n",
    "        self.number_of_article = 0## has infoBox \n",
    "        self.number_of_total_article = 0 ## total article in the WikiDump data\n",
    "        self.no_infoBox_count = 0\n",
    "        self.non_article_count = 0 \n",
    "        self.info_box_types = []\n",
    "        \n",
    "\n",
    "        self.allArticles_path = \"\"\n",
    "        self.infoBoxTypes_path = \"\"        \n",
    "        self.log_path = \"\"\n",
    "        #generation of tree\n",
    "        tree = ET.parse(file_path)\n",
    "        self.root = tree.getroot()\n",
    "        \n",
    "    def get_title(self,page):\n",
    "        return page.find('{http://www.mediawiki.org/xml/export-0.10/}title').text\n",
    "    def get_id(self,page):\n",
    "        return page.find('{http://www.mediawiki.org/xml/export-0.10/}id').text\n",
    "    def get_all_text(self,page):\n",
    "        Whole_ARC = page.find('{http://www.mediawiki.org/xml/export-0.10/}revision')\n",
    "        Whole_ARC_without_many_unnecessary_tag = Whole_ARC.find('{http://www.mediawiki.org/xml/export-0.10/}text', {'xml:space': 'preserve'})\n",
    "        return Whole_ARC_without_many_unnecessary_tag.text\n",
    "    \n",
    "    def save_articles(self,article):\n",
    "        with open(self.allArticles_path, \"ab\")  as f:\n",
    "            f.write(article.get_Saving_String())\n",
    "            \n",
    "    def save_infoBoxTypes(self):\n",
    "        self.info_box_types = self.unique( self.info_box_types )\n",
    "        with open(self.infoBoxTypes_path, \"ab\")  as f:\n",
    "            for info_b_type in self.info_box_types:\n",
    "                f.write(str(info_b_type[0].encode('utf-8'))+'#'+str(info_b_type[1])+'\\n')\n",
    "                \n",
    "    def save_log(self,title, text):\n",
    "        with open(self.log_path, \"ab\") as myfile:\n",
    "            myfile.write(title +\" ---------\\n\")\n",
    "            myfile.write( text+\"\\n\")\n",
    "            myfile.write(\"--------------------------\\n\\n\")            \n",
    "\n",
    "    def unique(self,list1):\n",
    "        c = Counter( list1 )\n",
    "        return list(c.items())\n",
    "    def extract_pages(self,allArticles_path,infoBoxTypes_path,log_path):        \n",
    "        '''This function must extract all pages with InfoBox,and also info boz type must be counted'''\n",
    "        self.allArticles_path = allArticles_path\n",
    "        self.infoBoxTypes_path = infoBoxTypes_path \n",
    "        self.log_path = log_path\n",
    "   \n",
    "        \n",
    "        for page in self.root.findall('{http://www.mediawiki.org/xml/export-0.10/}page'):\n",
    "            self.number_of_total_article +=1\n",
    "            article = Article()\n",
    "            \n",
    "            # Getting title, id, whole text of the article\n",
    "            article.set_title( title = self.get_title(page) )\n",
    "            article.set_id( id = self.get_id(page) )\n",
    "            article_text = self.get_all_text(page)\n",
    "            # -----\n",
    "            \n",
    "            # if there is no article text\n",
    "            if article_text == None:\n",
    "                self.non_article_count +=1\n",
    "                continue\n",
    "            # -----\n",
    "            \n",
    "            # Is the article contains a info box or not\n",
    "            if 'bilgi kutusu' in article_text :\n",
    "                pass\n",
    "            else:\n",
    "                self.no_infoBox_count +=1\n",
    "                continue\n",
    "            # -----\n",
    "            \n",
    "            article.set_article_text_bulk ( bulk_text = article_text )\n",
    "            \n",
    "            # cleaning the article text     \n",
    "            try:\n",
    "                article.parse_infoBox()\n",
    "                article.clean_infoBox()\n",
    "                article.parse_firstPragraph()\n",
    "            except Exception as e:\n",
    "                print e\n",
    "                self.error_count +=1\n",
    "                continue\n",
    "            # -----\n",
    "            \n",
    "            self.info_box_types.append( article.get_infoBoxType() )\n",
    "            self.number_of_article +=1\n",
    "            self.save_articles(article)\n",
    "        self.save_infoBoxTypes()\n",
    "        s =  \"\\n#Scanned Total Article {} \\n#Scanned Article that has InfoBox {} \\n#No InfoBox Count {}\\n#None Article Count {} (article Area is None)\\n#Error Count {} (infoBox clean or getting paragraph error)\".\\\n",
    "                        format(self.number_of_total_article,\n",
    "                               self.number_of_article,\n",
    "                               self.no_infoBox_count,\n",
    "                               self.non_article_count,\n",
    "                               self.error_count)\n",
    "        print s\n",
    "        self.save_log(\"Wiki Dump Extracted\",s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article:\n",
    "    def _init_(self):\n",
    "        self.article_id = -1\n",
    "        self.article_title = \"\"\n",
    "        self.article_info_box = \"\"\n",
    "        self.article_text_bulk = \"\"\n",
    "        self.article_info_box_clean = \"\"\n",
    "        self.article_info_box_type = \"\"\n",
    "        self.article_first_paragraph = \"\"\n",
    "\n",
    "\n",
    "\n",
    "    def set_id(self,id):\n",
    "        self.article_id = id\n",
    "    def set_title(self,title):\n",
    "        self.article_title = title\n",
    "    def set_infoBox(self,infoBox):\n",
    "        self.article_info_box = infoBox\n",
    "    def set_infoBox_clean(self,infoBox_clean):\n",
    "        self.article_info_box_clean = infoBox_clean\n",
    "    def set_infoBox_type(self,infoBox_type):\n",
    "        self.article_info_box_type = infoBox_type\n",
    "    def set_infoBox_firts_paragraph(self,paragraph):\n",
    "        self.article_first_paragraph = paragraph\n",
    "    def set_article_text_bulk(self,bulk_text):\n",
    "        self.article_text_bulk = bulk_text\n",
    "    def get_infoBoxType(self):\n",
    "        return self.article_info_box_type\n",
    "    #----\n",
    "    def parse_infoBox(self):\n",
    "        text = self.article_text_bulk\n",
    "        article_txt = text[:text.find(\"==\")]\n",
    "        infoBoxType = (re.search('{{(.*) bilgi kutusu', article_txt)).group(1)\n",
    "        self.set_infoBox_type(infoBoxType)\n",
    "        \n",
    "        # a little cleaning\n",
    "        temp = article_txt.split('\\n')\n",
    "        for i in range(0,len(temp)):\n",
    "            if 'bilgi kutusu' in temp[i]:\n",
    "                break\n",
    "            else:\n",
    "                temp[i]=''\n",
    "        article_txt = '\\n'.join(temp)\n",
    "        \n",
    "        infoBox = self.stack_check(article_txt)\n",
    "        self.set_infoBox( infoBox )\n",
    "\n",
    "    def clean_infoBox(self):\n",
    "        infoBox = self.article_info_box\n",
    "        \n",
    "        #some cleanings\n",
    "        infoBox = re.sub(r\"\\[\\[Dosya.*\\]\\]\",\"\",infoBox)\n",
    "        infoBox = re.sub(r\"<br/>\",\"\",infoBox)\n",
    "        infoBox = re.sub(r\"<br />\",\"\",infoBox)    \n",
    "        infoBox = re.sub(r\"<br>\",\"\",infoBox)\n",
    "        infoBox = infoBox.replace('[[','').replace(']]','').replace(\"\\'\\'\\'\",'').replace(\"''\",'')\n",
    "        infoBox = infoBox.replace('{{','').replace('}}','')\n",
    "        infoBox = re.sub(r\"<ref(.|\\n)*</ref>\",\"\",infoBox)\n",
    "        infoBox = infoBox.replace(u'\\xa0', u' ')\n",
    "        \n",
    "        #empty place will be deleted\n",
    "        t = infoBox.split('\\n')\n",
    "        infoBox = []\n",
    "        for i in range(0,len(t)):\n",
    "            line = t[i]\n",
    "            if ' ' == line or ' ' == line or '  ' == line or '' == line:\n",
    "                continue\n",
    "            elif line.count('=') == 1:\n",
    "                if len(line[line.find('='):].replace(' ','')) <3:\n",
    "                    continue\n",
    "                else:\n",
    "                    infoBox.append(t[i])\n",
    "            else:\n",
    "                infoBox.append(t[i])\n",
    "        infoBox = '\\n'.join(infoBox)\n",
    "        self.set_infoBox_clean( '{{'+infoBox+'}}' )\n",
    "    \n",
    "    def parse_firstPragraph(self):\n",
    "        infoBox = self.article_info_box\n",
    "        article_text = self.article_text_bulk\n",
    "        #generate end of the infobox to end of the paragrafs\n",
    "        paragraph = article_text[:article_text.find(\"==\")]\n",
    "        paragraph = paragraph[paragraph.find(infoBox)+len(infoBox):]\n",
    "\n",
    "        # nd of the infobox to end of the ONE paragraf\n",
    "        paragraph_number = paragraph.count('\\n\\n')\n",
    "        for i in range(0,paragraph_number-1):\n",
    "            paragraph = paragraph [:paragraph.rfind('\\n\\n')]\n",
    "        self.set_infoBox_firts_paragraph( paragraph ) \n",
    "    #----\n",
    "    def stack_check(self,text):\n",
    "        stack = Stack()\n",
    "        lines = text.split(\"\\n\")\n",
    "        isFirst = True\n",
    "        isFinish = False\n",
    "        infoBox = []\n",
    "        for line in lines:\n",
    "            openB = line.count(\"{{\")\n",
    "            closeB = line.count(\"}}\")\n",
    "            for i in range(0,openB):\n",
    "                stack.push('{{')\n",
    "            if isFirst == True and openB!=0:\n",
    "                isFirst=False\n",
    "                n = stack.pop()\n",
    "            for i in range(0,closeB):\n",
    "                if stack.size()>0:\n",
    "                    if stack.peek() == '{{':\n",
    "                        n = stack.pop()\n",
    "                    else:\n",
    "                        isFinish = True\n",
    "                else:\n",
    "                    isFinish = True\n",
    "            infoBox.append(line)\n",
    "            if isFinish == True:\n",
    "                break\n",
    "        infoBox = '\\n'.join(infoBox)\n",
    "        return infoBox\n",
    "    \n",
    "    def get_Saving_String(self):\n",
    "        r = self.article_id, \\\n",
    "            self.article_title, \\\n",
    "            self.article_info_box_type, \\\n",
    "            self.article_info_box , \\\n",
    "            self.article_info_box_clean, \\\n",
    "            self.article_first_paragraph \n",
    "        saving_string =   str(r[0].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[1].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[2].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[3].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[5].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'\\n\\n\\n' \n",
    "        #str(r[4].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "        return saving_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files():\n",
    "    today = date.today().strftime('<%Y-%m-%d>')\n",
    "    mypath = '../'+today+'Outputs_Bulk'\n",
    "    if not os.path.isdir(mypath):\n",
    "        os.makedirs(mypath)\n",
    "    article_path = '../'+today+'Outputs_Bulk/All_Article.txt'\n",
    "    counter_path = '../'+today+'Outputs_Bulk/infoBoxType_Counter.txt'\n",
    "    log_path = '../'+today+'Outputs_Bulk/Extractor Report.txt'\n",
    "    f= open(article_path,\"w\")\n",
    "    f= open(counter_path,\"w\")\n",
    "    f= open(log_path,\"w\")\n",
    "    return article_path,counter_path,log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "article_path,counter_path,log_path = create_files()\n",
    "wp = WikiDumpParser('../wikidump.xml')\n",
    "wp.extract_pages(article_path,counter_path,log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

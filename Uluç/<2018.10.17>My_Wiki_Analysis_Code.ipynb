{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author = Ulu√ß Furkan Vardar\n",
    "\n",
    "Version = 3.0\n",
    "\n",
    "Using this code you can manipulate Wiki Dump data.\n",
    "the data you will obtain;\n",
    "\t* article id\n",
    "\t* article title\n",
    "\t* Article infoBox type\n",
    "\t* article infoBox as text (empty places thrown or normal)\n",
    "\t* the first paragraph of the article\n",
    "\n",
    "\n",
    "The output of the program is placed in an output folder created for that date. (EX Folder name: <2018-10-07>Output/ )\n",
    "The output consists of two .txt files. One of them holds the above information. \n",
    "\tfile named '<2018-10-07>All_Article.txt'\n",
    "\t(Format: ...\\n\\n\\narticle_id#article_title#infoBoxType#infoBox#first_paragraph\\n\\n\\n...)\n",
    "\n",
    "The other is a hit counter output for every infoBox type.\n",
    "\tfile named '<2018-10-07>infoBoxType_Counter.txt'\n",
    "\t(Format: ...\\ninfoBoxType#hit_counter\\n...)\n",
    "\n",
    "Also, A Log file is generated and the important things about the data processing area are printed...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libs\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "from datetime import date\n",
    "import argparse\n",
    "import codecs\n",
    "import time\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "global today\n",
    "global counter_path\n",
    "global article_path\n",
    "global number_of_total_article\n",
    "global error_count\n",
    "global no_infoBox_count\n",
    "global non_article_count\n",
    "global log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stack:\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "\n",
    "    def isEmpty(self):\n",
    "        return self.items == []\n",
    "\n",
    "    def push(self, item):\n",
    "        self.items.append(item)\n",
    "\n",
    "    def pop(self):\n",
    "        return self.items.pop()\n",
    "\n",
    "    def peek(self):\n",
    "        return self.items[len(self.items)-1]\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article:\n",
    "    def _init_(self):\n",
    "        self.article_id = -1\n",
    "        self.article_title = \"\"\n",
    "        self.article_info_box = \"\"\n",
    "        self.article_info_box_clean = \"\"\n",
    "        self.article_info_box_type = \"\"\n",
    "        self.article_first_paragraph = \"\"\n",
    "    def __iter__(self):\n",
    "        return self.get_Saving_String(self)\n",
    "    def set_id(self,id):\n",
    "        self.article_id = id\n",
    "    def set_title(self,title):\n",
    "        self.article_title = title\n",
    "    def set_infoBox(self,infoBox):\n",
    "        self.article_info_box = infoBox\n",
    "    def set_infoBox_clean(self,infoBox_clean):\n",
    "        self.article_info_box_clean = infoBox_clean\n",
    "    def set_infoBox_type(self,infoBox_type):\n",
    "        self.article_info_box_type = infoBox_type\n",
    "    def set_infoBox_firts_paragraph(self,paragraph):\n",
    "        self.article_first_paragraph = paragraph\n",
    "    def get_Saving_String(self):\n",
    "        r = self.article_id, \\\n",
    "            self.article_title, \\\n",
    "            self.article_info_box_type, \\\n",
    "            self.article_info_box , \\\n",
    "            self.article_info_box_clean, \\\n",
    "            self.article_first_paragraph \n",
    "        saving_string =   str(r[0].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[1].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[2].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[3].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[4].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[5].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'\\n\\n\\n' \n",
    "        return saving_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_check(text):\n",
    "    stack = Stack()\n",
    "    lines = text.split(\"\\n\")\n",
    "    isFirst = True\n",
    "    isFinish = False\n",
    "    infoBox = []\n",
    "    for line in lines:\n",
    "        openB = line.count(\"{{\")\n",
    "        closeB = line.count(\"}}\")\n",
    "        for i in range(0,openB):\n",
    "            stack.push('{{')\n",
    "        if isFirst == True and openB!=0:\n",
    "            isFirst=False\n",
    "            n = stack.pop()\n",
    "        for i in range(0,closeB):\n",
    "            if stack.size()>0:\n",
    "                if stack.peek() == '{{':\n",
    "                    n = stack.pop()\n",
    "                else:\n",
    "                    isFinish = True\n",
    "            else:\n",
    "                isFinish = True\n",
    "        infoBox.append(line)\n",
    "        if isFinish == True:\n",
    "            break\n",
    "    infoBox = '\\n'.join(infoBox)\n",
    "    return infoBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_infoBox(text):\n",
    "    article_txt = text[:text.find(\"==\")]\n",
    "    infoBoxType = (re.search('{{(.*) bilgi kutusu', article_txt)).group(1)\n",
    "    temp =article_txt.split('\\n')\n",
    "    for i in range(0,len(temp)):\n",
    "        if 'bilgi kutusu' in temp[i]:\n",
    "            break\n",
    "        else:\n",
    "            temp[i]=''\n",
    "    article_txt = '\\n'.join(temp)\n",
    "    infoBox = stack_check(article_txt)\n",
    "    return infoBoxType,infoBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_infoBox(infoBox):\n",
    "    #some cleanings\n",
    "    infoBox = re.sub(r\"\\[\\[Dosya.*\\]\\]\",\"\",infoBox)\n",
    "    infoBox = re.sub(r\"<br/>\",\"\",infoBox)\n",
    "    infoBox = re.sub(r\"<br />\",\"\",infoBox)    \n",
    "    infoBox = re.sub(r\"<br>\",\"\",infoBox)\n",
    "    infoBox = infoBox.replace('[[','').replace(']]','').replace(\"\\'\\'\\'\",'').replace(\"''\",'')\n",
    "    infoBox = infoBox.replace('{{','').replace('}}','')\n",
    "    infoBox = re.sub(r\"<ref(.|\\n)*</ref>\",\"\",infoBox)\n",
    "    infoBox = infoBox.replace(u'\\xa0', u' ')\n",
    "\n",
    "    #empty place will be deleted\n",
    "    t = infoBox.split('\\n')\n",
    "    infoBox = []\n",
    "    for i in range(0,len(t)):\n",
    "        line = t[i]\n",
    "        if ' ' == line or ' ' == line or '  ' == line or '' == line:\n",
    "            continue\n",
    "        elif line.count('=') == 1:\n",
    "            if len(line[line.find('='):].replace(' ','')) <3:\n",
    "                continue\n",
    "            else:\n",
    "                infoBox.append(t[i])\n",
    "        else:\n",
    "            infoBox.append(t[i])\n",
    "    infoBox = '\\n'.join(infoBox)\n",
    "    return '{{'+infoBox+'}}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_paragraf(infoBox,article_text):\n",
    "    #generate end of the infobox to end of the paragrafs\n",
    "    paragraf = article_text[:article_text.find(\"==\")]\n",
    "    paragraf = paragraf[paragraf.find(infoBox)+len(infoBox):]\n",
    "\n",
    "    # nd of the infobox to end of the ONE paragraf\n",
    "    paragraf_number = paragraf.count('\\n\\n')\n",
    "    for i in range(0,paragraf_number-1):\n",
    "        paragraf = paragraf [:paragraf.rfind('\\n\\n')]\n",
    "\n",
    "    #some cleaning operations from tags etc.\n",
    "    paragraf = re.sub(r\"\\[\\[Dosya.*\\]\\]\",\"\",paragraf)\n",
    "    paragraf = re.sub(r\"<ref(.|\\n)*</ref>\",\"\",paragraf)\n",
    "    paragraf = re.sub(r\"\\n\",\"\",paragraf)\n",
    "    paragraf = paragraf.replace('[[','').replace(']]','').replace(\"'''\",'').replace(\"''\",'')\n",
    "    paragraf = re.sub(r\"{{.*}}\",\"\",paragraf)\n",
    "\n",
    "    #cleaning | piped worlds\n",
    "    p = paragraf.split(' ')\n",
    "    for i in range(0,len(p)):\n",
    "        if '|' in p[i]:\n",
    "            p[i] = p[i].split('|')[1]\n",
    "    paragraf = ' '.join(p)\n",
    "    if paragraf.count('}}') == 1 :\n",
    "        paragraf =paragraf[paragraf.index('}}')+2:]\n",
    "    return paragraf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1):\n",
    "    c = Counter( list1 )\n",
    "    return list(c.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files():\n",
    "    global today\n",
    "    global counter_path\n",
    "    global article_path\n",
    "    global log_path\n",
    "    today = date.today().strftime('<%Y-%m-%d>')\n",
    "    mypath = './'+today+'Outputs'\n",
    "    if not os.path.isdir(mypath):\n",
    "        os.makedirs(mypath)\n",
    "    article_path = './'+today+'Outputs/'+today+'All_Article.txt'\n",
    "    counter_path = './'+today+'Outputs/'+today+'infoBoxType_Counter.txt'\n",
    "    log_path = './'+today+'Outputs/'+today+'Extractor Report.txt'\n",
    "    f= open(article_path,\"w\")\n",
    "    f= open(counter_path,\"w\")\n",
    "    f= open(log_path,\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_article(article): \n",
    "    global article_path\n",
    "    with open(article_path, \"ab\")  as f:\n",
    "        f.write(article.get_Saving_String())\n",
    "def save_infoBoxTypes(infoBox_types):\n",
    "    print \"Info Box Type Made Unique\"\n",
    "    infoBox_types = unique(infoBox_types)\n",
    "    global counter_path\n",
    "    with open(counter_path, \"ab\")  as f:\n",
    "        for info_b_type in infoBox_types:\n",
    "            f.write(str(info_b_type[0].encode('utf-8'))+'#'+str(info_b_type[1])+'\\n')\n",
    "def save_log(title, text):\n",
    "    global log_path\n",
    "    with open(log_path, \"ab\") as myfile:\n",
    "        myfile.write(title +\" ---------\\n\")\n",
    "        myfile.write( text+\"\\n\")\n",
    "        myfile.write(\"--------------------------\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseXML(path):\n",
    "    global error_count\n",
    "    global number_of_article ## has infoBox \n",
    "    global number_of_total_article ## total article in the WikiDump data\n",
    "    global no_infoBox_count\n",
    "    global non_article_count\n",
    "\n",
    "    number_of_total_article = 0\n",
    "    number_of_article = 0\n",
    "    non_article_count = 0 \n",
    "    no_infoBox_count = 0\n",
    "    error_count = 0\n",
    "    #generation of tree\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    #for to collect diffrent infoBoxType\n",
    "    infoBox_types = []\t\n",
    "    for page in root.findall('{http://www.mediawiki.org/xml/export-0.10/}page'):\n",
    "        number_of_total_article +=1\n",
    "        article = Article()\n",
    "        article.set_title( page.find('{http://www.mediawiki.org/xml/export-0.10/}title').text )\n",
    "        article.set_id( page.find('{http://www.mediawiki.org/xml/export-0.10/}id').text )\n",
    "        # Whole_text of the article\n",
    "        Whole_ARC = page.find('{http://www.mediawiki.org/xml/export-0.10/}revision')\n",
    "        Whole_ARC_without_many_unnecessary_tag = Whole_ARC.find('{http://www.mediawiki.org/xml/export-0.10/}text', {'xml:space': 'preserve'})\n",
    "        article_text = Whole_ARC_without_many_unnecessary_tag.text\n",
    "        if article_text == None:\n",
    "            non_article_count +=1\n",
    "            continue\n",
    "        if 'bilgi kutusu' in article_text  :\n",
    "            pass\n",
    "        else:\n",
    "            no_infoBox_count +=1\n",
    "            continue\n",
    "        try:\n",
    "            infoBoxType,infoBox = take_infoBox(article_text)\n",
    "            paragraf = take_paragraf(infoBox,article_text)\n",
    "            infoBox_clean = clean_infoBox(infoBox)\n",
    "        except Exception as e:\n",
    "            error_count +=1\n",
    "            continue\n",
    "        infoBox_types.append(infoBoxType)\n",
    "        article.set_infoBox(infoBox)\n",
    "        article.set_infoBox_type(infoBoxType)\n",
    "        article.set_infoBox_clean(infoBox_clean)\n",
    "        article.set_infoBox_firts_paragraph(paragraf)\n",
    "        number_of_article +=1\n",
    "\n",
    "\n",
    "\n",
    "        save_article(article)\n",
    "        print \"Scanned Total Article {} , Scanned Article that has InfoBox {}\".format(number_of_total_article,number_of_article)\n",
    "\n",
    "    save_infoBoxTypes(infoBox_types)\n",
    "\n",
    "    print \"--------------------------\"\n",
    "    s =  \"Scanned Total Article {} \\nScanned Article that has InfoBox {} \\nNo InfoBox Count {}\\nNone Article Count {}\\nError Count {}\".\\\n",
    "                    format(number_of_total_article,number_of_article,no_infoBox_count,non_article_count,error_count)\n",
    "    print s\n",
    "    save_log(\"Wiki Dump Extracted\",s)\n",
    "\n",
    "def help():\n",
    "    usage = \" my_wikiExtractor.py -h \\n\\\n",
    "     my_wikiExtractor.py -f \\\"path.xml\\\" \\n\\\n",
    "     my_wikiExtractor.py -file \\\"path.xml\\\" \\n\\\n",
    "     can be use like this. \\n\\n\"\n",
    "    print usage\n",
    "\n",
    "def main():\n",
    "    argument_len=len(sys.argv)\n",
    "    arguments = sys.argv\n",
    "    if argument_len == 3 and ( arguments[1] == \"-file\" or arguments[1] == \"-f\"):\n",
    "        create_files()\n",
    "        parseXML(arguments[2].decode('utf-8'))\n",
    "    elif arguments[1] == '-h':\n",
    "        help()\n",
    "    else :\n",
    "        help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article:\n",
    "    def _init_(self):\n",
    "        self.article_id = -1\n",
    "        self.article_title = \"\"\n",
    "        self.article_info_box = \"\"\n",
    "        self.article_text_bulk = \"\"\n",
    "        self.article_info_box_clean = \"\"\n",
    "        self.article_info_box_type = \"\"\n",
    "        self.article_first_paragraph = \"\"\n",
    "\n",
    "\n",
    "\n",
    "    def set_id(self,id):\n",
    "        self.article_id = id\n",
    "    def set_title(self,title):\n",
    "        self.article_title = title\n",
    "    def set_infoBox(self,infoBox):\n",
    "        self.article_info_box = infoBox\n",
    "    def set_infoBox_clean(self,infoBox_clean):\n",
    "        self.article_info_box_clean = infoBox_clean\n",
    "    def set_infoBox_type(self,infoBox_type):\n",
    "        self.article_info_box_type = infoBox_type\n",
    "    def set_infoBox_firts_paragraph(self,paragraph):\n",
    "        self.article_first_paragraph = paragraph\n",
    "    def set_article_text_bulk(self,bulk_text):\n",
    "        self.article_text_bulk = bulk_text\n",
    "    def get_infoBoxType(self):\n",
    "        return self.article_info_box_type\n",
    "    #----\n",
    "    def parse_infoBox(self):\n",
    "        text = self.article_text_bulk\n",
    "        article_txt = text[:text.find(\"==\")]\n",
    "        infoBoxType = (re.search('{{(.*) bilgi kutusu', article_txt)).group(1)\n",
    "        self.set_infoBox_type(infoBoxType)\n",
    "        \n",
    "        # a little cleaning\n",
    "        temp = article_txt.split('\\n')\n",
    "        for i in range(0,len(temp)):\n",
    "            if 'bilgi kutusu' in temp[i]:\n",
    "                break\n",
    "            else:\n",
    "                temp[i]=''\n",
    "        article_txt = '\\n'.join(temp)\n",
    "        \n",
    "        infoBox = stack_check(article_txt)\n",
    "        self.set_infoBox( infoBox )\n",
    "\n",
    "    def clean_infoBox(self):\n",
    "        infoBox = self.article_info_box\n",
    "        #some cleanings\n",
    "        infoBox = re.sub(r\"\\[\\[Dosya.*\\]\\]\",\"\",infoBox)\n",
    "        infoBox = re.sub(r\"<br/>\",\"\",infoBox)\n",
    "        infoBox = re.sub(r\"<br />\",\"\",infoBox)    \n",
    "        infoBox = re.sub(r\"<br>\",\"\",infoBox)\n",
    "        infoBox = infoBox.replace('[[','').replace(']]','').replace(\"\\'\\'\\'\",'').replace(\"''\",'')\n",
    "        infoBox = infoBox.replace('{{','').replace('}}','')\n",
    "        infoBox = re.sub(r\"<ref(.|\\n)*</ref>\",\"\",infoBox)\n",
    "        infoBox = infoBox.replace(u'\\xa0', u' ')\n",
    "        #empty place will be deleted\n",
    "        t = infoBox.split('\\n')\n",
    "        infoBox = []\n",
    "        for i in range(0,len(t)):\n",
    "            line = t[i]\n",
    "            if ' ' == line or ' ' == line or '  ' == line or '' == line:\n",
    "                continue\n",
    "            elif line.count('=') == 1:\n",
    "                if len(line[line.find('='):].replace(' ','')) <3:\n",
    "                    continue\n",
    "                else:\n",
    "                    infoBox.append(t[i])\n",
    "            else:\n",
    "                infoBox.append(t[i])\n",
    "        infoBox = '\\n'.join(infoBox)\n",
    "        self.set_infoBox_clean( '{{'+infoBox+'}}' )\n",
    "    \n",
    "    def parse_firstPragraph(self):\n",
    "        infoBox = self.article_info_box\n",
    "        article_text = self.article_text_bulk\n",
    "        #generate end of the infobox to end of the paragrafs\n",
    "        paragraph = article_text[:article_text.find(\"==\")]\n",
    "        paragraph = paragraph[paragraph.find(infoBox)+len(infoBox):]\n",
    "\n",
    "        # nd of the infobox to end of the ONE paragraf\n",
    "        paragraph_number = paragraph.count('\\n\\n')\n",
    "        for i in range(0,paragraph_number-1):\n",
    "            paragraph = paragraph [:paragraph.rfind('\\n\\n')]\n",
    "        self.set_infoBox_firts_paragraph( paragraph ) \n",
    "    #----\n",
    "    def stack_check(text):\n",
    "        stack = Stack()\n",
    "        lines = text.split(\"\\n\")\n",
    "        isFirst = True\n",
    "        isFinish = False\n",
    "        infoBox = []\n",
    "        for line in lines:\n",
    "            openB = line.count(\"{{\")\n",
    "            closeB = line.count(\"}}\")\n",
    "            for i in range(0,openB):\n",
    "                stack.push('{{')\n",
    "            if isFirst == True and openB!=0:\n",
    "                isFirst=False\n",
    "                n = stack.pop()\n",
    "            for i in range(0,closeB):\n",
    "                if stack.size()>0:\n",
    "                    if stack.peek() == '{{':\n",
    "                        n = stack.pop()\n",
    "                    else:\n",
    "                        isFinish = True\n",
    "                else:\n",
    "                    isFinish = True\n",
    "            infoBox.append(line)\n",
    "            if isFinish == True:\n",
    "                break\n",
    "        infoBox = '\\n'.join(infoBox)\n",
    "        return infoBox\n",
    "    \n",
    "    def get_Saving_String(self):\n",
    "        r = self.article_id, \\\n",
    "            self.article_title, \\\n",
    "            self.article_info_box_type, \\\n",
    "            self.article_info_box , \\\n",
    "            self.article_info_box_clean, \\\n",
    "            self.article_first_paragraph \n",
    "        saving_string =   str(r[0].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[1].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[2].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[3].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[4].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'#'+\\\n",
    "                            str(r[5].encode('utf-8')).replace('\\n','<nl>').replace('#','') +'\\n\\n\\n' \n",
    "        return saving_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "class WikiDumpParser:\n",
    "    def __init__(self,file_path):\n",
    "        self.error_count = 0\n",
    "        self.number_of_article = 0## has infoBox \n",
    "        self.number_of_total_article = 0 ## total article in the WikiDump data\n",
    "        self.no_infoBox_count = 0\n",
    "        self.non_article_count = 0 \n",
    "        self.info_box_types = []\n",
    "        \n",
    "\n",
    "        self.allArticles_path = \"\"\n",
    "        self.infoBoxTypes_path = \"\"        \n",
    "        self.log_path = \"\"\n",
    "        #generation of tree\n",
    "        tree = ET.parse(file_path)\n",
    "        self.root = tree.getroot()\n",
    "        \n",
    "    def get_title(self,page):\n",
    "        return page.find('{http://www.mediawiki.org/xml/export-0.10/}title').text\n",
    "    def get_id(self,page):\n",
    "        return page.find('{http://www.mediawiki.org/xml/export-0.10/}id').text\n",
    "    def get_all_text(self,page):\n",
    "        Whole_ARC = page.find('{http://www.mediawiki.org/xml/export-0.10/}revision')\n",
    "        Whole_ARC_without_many_unnecessary_tag = Whole_ARC.find('{http://www.mediawiki.org/xml/export-0.10/}text', {'xml:space': 'preserve'})\n",
    "        return Whole_ARC_without_many_unnecessary_tag.text\n",
    "    def save_articles(self,article):\n",
    "        with open(self.allArticles_path, \"ab\")  as f:\n",
    "            f.write(article.get_Saving_String())\n",
    "    def save_infoBoxTypes(self):\n",
    "        self.info_box_types = self.unique( self.info_box_types )\n",
    "        with open(self.infoBoxTypes_path, \"ab\")  as f:\n",
    "            for info_b_type in self.info_box_types:\n",
    "                f.write(str(info_b_type[0].encode('utf-8'))+'#'+str(info_b_type[1])+'\\n')\n",
    "    def save_log(self,title, text):\n",
    "        with open(self.log_path, \"ab\") as myfile:\n",
    "            myfile.write(title +\" ---------\\n\")\n",
    "            myfile.write( text+\"\\n\")\n",
    "            myfile.write(\"--------------------------\\n\\n\")            \n",
    "\n",
    "    def unique(self,list1):\n",
    "        c = Counter( list1 )\n",
    "        return list(c.items())\n",
    "    def extract_pages(self,allArticles_path,infoBoxTypes_path,log_path):        \n",
    "        '''This function must extract all pages with InfoBox,and also info boz type must be counted'''\n",
    "        self.allArticles_path = allArticles_path\n",
    "        self.infoBoxTypes_path = infoBoxTypes_path \n",
    "        self.log_path = log_path\n",
    "        \n",
    "        \n",
    "        animation = \"|/-\\\\\"\n",
    "        for page in self.root.findall('{http://www.mediawiki.org/xml/export-0.10/}page'):\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            self.number_of_total_article +=1\n",
    "            article = Article()\n",
    "            \n",
    "            # Getting title, id, whole text of the article\n",
    "            article.set_title( title = self.get_title(page) )\n",
    "            article.set_id( id = self.get_id(page) )\n",
    "            article_text = self.get_all_text(page)\n",
    "            # -----\n",
    "            \n",
    "            # if there is no article text\n",
    "            if article_text == None:\n",
    "                self.non_article_count +=1\n",
    "                continue\n",
    "            # -----\n",
    "            \n",
    "            # Is the article contains a info box or not\n",
    "            if 'bilgi kutusu' in article_text :\n",
    "                pass\n",
    "            else:\n",
    "                self.no_infoBox_count +=1\n",
    "                continue\n",
    "            # -----\n",
    "            \n",
    "            article.set_article_text_bulk ( bulk_text = article_text )\n",
    "            \n",
    "            # cleaning the article text     \n",
    "            try:\n",
    "                article.parse_infoBox()\n",
    "                article.clean_infoBox()\n",
    "                article.parse_firstPragraph()\n",
    "            except Exception as e:\n",
    "                self.error_count +=1\n",
    "                continue\n",
    "            # -----\n",
    "            \n",
    "            self.info_box_types.append( article.get_infoBoxType() )\n",
    "            self.number_of_article +=1\n",
    "            \n",
    "            self.save_articles(article)\n",
    "        self.save_infoBoxTypes()\n",
    "        s =  \"\\n#Scanned Total Article {} \\n#Scanned Article that has InfoBox {} \\n#No InfoBox Count {}\\n#None Article Count {} (article Area is None)\\n#Error Count {} (infoBox clean or getting paragraph error)\".\\\n",
    "                        format(self.number_of_total_article,\n",
    "                               self.number_of_article,\n",
    "                               self.no_infoBox_count,\n",
    "                               self.non_article_count,\n",
    "                               self.error_count)\n",
    "        print s\n",
    "        self.save_log(\"Wiki Dump Extracted\",s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp = WikiDumpParser('./part.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#Scanned Total Article 359 \n",
      "#Scanned Article that has InfoBox 0 \n",
      "#No InfoBox Count 330\n",
      "#None Article Count 0 (article Area is None)\n",
      "#Error Count 29 (infoBox clean or getting paragraph error)\n"
     ]
    }
   ],
   "source": [
    "wp.extract_pages('./article.txt','./type.txt','./log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\End!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "animation = \"|/-\\\\\"\n",
    "\n",
    "for i in range(100):\n",
    "    time.sleep(0.1)\n",
    "    sys.stdout.write(\"\\r\" + animation[i % len(animation)])\n",
    "    sys.stdout.flush()\n",
    "    #do something\n",
    "print(\"End!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

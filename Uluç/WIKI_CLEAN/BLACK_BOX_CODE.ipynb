{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../<2018-12-02>Outputs-BLACK BOX CODE/\n"
     ]
    }
   ],
   "source": [
    "from my_logging import my_outputs_and_logging\n",
    "\n",
    "log = my_outputs_and_logging('BLACK BOX CODE')\n",
    "\n",
    "print log.get_output_path()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First data Reading from Bulk data and clean it(with lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Articles read -> 180702\n",
      "#Articles read successfully -> 177321\n",
      "#Articles saved successfully -> 177321\n"
     ]
    }
   ],
   "source": [
    "from file_commander import my_file_commander\n",
    "\n",
    "commander = my_file_commander()\n",
    "### TO READ\n",
    "article_path ='/Users/uluc/Desktop/Bitirme/Wikiparse_WorkSpace/<2018.10.-->Wiki/<2018-10-20>Outputs_Bulk/All_Article.txt'\n",
    "splitter_patter = '\\n\\n\\n'\n",
    "dataContains_tuples = ['id','title','infoBox_type','text_infoBox','bulk_paragraph']\n",
    "articles = commander.my_tub_file_reader(article_path,splitter_patter,dataContains_tuples)\n",
    "\n",
    "##3 this part otomaticley parse infobox\n",
    "\n",
    "###Save this clean Data\n",
    "### TO SAVE\n",
    "dataContains_tuples = ['id','title','infoBox_type','bulk_infoBox','clean_infoBox','bulk_paragraph']\n",
    "commander.my_tub_file_recorder(log.get_output_path()+'All_Articles.txt',articles,'\\n\\n\\n',dataContains_tuples)\n",
    "\n",
    "log.save_log('Read Bulk Data',u'#Articles read -> '+str(commander.read_total)+'\\n#Articles read successfully -> '+str(commander.read_successfully)+'\\n#Articles saved successfully -> '+str(commander.saved_successfully))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Articles saved successfully -> 53115\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sapsik_bir_Analyser import Article_Analyser\n",
    "log.add_splitter()\n",
    "Analysis_Article = Article_Analyser(articles)\n",
    "\n",
    "mypath = log.get_output_path() +'InfoBoxType_Analysis/'\n",
    "\n",
    "# > 4\n",
    "all_categories_greater_4 = Analysis_Article.get_all_uniq_infoBoxTypes_as_list(4)\n",
    "log.logging('#Total Uniq InfoBox Type ( > 4 ) : '+ str(len(all_categories_greater_4)))\n",
    "for one in all_categories_greater_4 : \n",
    "    log.create_a_file_in_a_folder('InfoBoxType_Analysis','all_categories( > 4 )',one.encode('utf-8'))\n",
    "Analysis_Article.draw_Repetition_of_all_InfoBoxTypes(mypath,'all_categories( > 4 )',4)\n",
    "\n",
    "# > 100\n",
    "all_categories_greater_100 = Analysis_Article.get_all_uniq_infoBoxTypes_as_list(100)\n",
    "Analysis_Article.draw_Repetition_of_all_InfoBoxTypes(mypath,'all_categories( > 100 )',100)\n",
    "log.logging('#Total Uniq InfoBox Type ( > 100 ) : '+ str(len(all_categories_greater_100)))\n",
    "for one in all_categories_greater_100 : \n",
    "    log.create_a_file_in_a_folder('InfoBoxType_Analysis','all_categories( > 100 )',one.encode('utf-8'))\n",
    "\n",
    "    \n",
    "# Our interested Info Box Types\n",
    "Interested_Info_Box_Types = ['Hakem' ,'Manken' ,'Makam sahibi' ,'Filozof' ,'Bilim insanı','Güreşçi' \n",
    "                             ,'Bilim adamı' ,'Sporcu' ,'Buz patencisi','Asker' \n",
    "                             ,'Voleybolcu' ,'Sanatçı','Futbolcu' ,'Oyuncu' \n",
    "                             ,'Müzik sanatçısı' ,'Yazar' ,'Kraliyet' ,'Tenis sporcu' ,'Profesyonel güreşçi'\n",
    "                             ,'Kişi' ,'Basketbolcu'] #'Çizgi roman karakteri' , 'Kurgusal karakter'\n",
    "log.save_log('Interested Info Box Types',json.dumps(Interested_Info_Box_Types, ensure_ascii=False, encoding='utf8').encode('utf-8'))\n",
    "\n",
    "Analysis_Article.ignore_other_types(Interested_Info_Box_Types)\n",
    "\n",
    "all_categories_interested = Analysis_Article.get_all_uniq_infoBoxTypes_as_list(100)\n",
    "\n",
    "Analysis_Article.draw_Repetition_of_all_InfoBoxTypes(mypath,'all_categories( > Interested Types )',1)\n",
    "log.logging('#Total Uniq InfoBox Type ( > Interested ) : '+ str(len(all_categories_interested)))\n",
    "log.logging('#Total Article ( > Interested ) : '+ str(len(Analysis_Article.articles)))\n",
    "for one in  all_categories_interested : \n",
    "    log.create_a_file_in_a_folder('InfoBoxType_Analysis','all_categories( > interested )',one.encode('utf-8'))\n",
    "    \n",
    "    \n",
    "###Save for all interested clean data\n",
    "### TO SAVE\n",
    "dataContains_tuples = ['id','title','infoBox_type','bulk_infoBox','clean_infoBox','bulk_paragraph']\n",
    "commander.my_tub_file_recorder(log.get_output_path()+'All_Articles_Interested.txt',Analysis_Article.articles,'\\n\\n\\n',dataContains_tuples)\n",
    "log.logging('#Total Articles saved successfully ( > Interested ) : '+ str(commander.saved_successfully))\n",
    "\n",
    "## for each info box type one example is saved\n",
    "import json\n",
    "examples = Analysis_Article.get_one_example_for_every_infoBox_type()\n",
    "for type_,one_example, in examples :\n",
    "    log.create_a_file_in_a_folder('InfoBoxType_Examples',type_,json.dumps(one_example, ensure_ascii=False, encoding='utf8',indent=4).encode('utf-8'))\n",
    "log.logging('For each info box type one example is saved')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Data Field Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = log.get_output_path() +'InfoBoxType_DataField_Counts'\n",
    "if not os.path.isdir(mypath):\n",
    "    os.makedirs(mypath)\n",
    "mypath = mypath+'/'    \n",
    "Analysis_Article.count_data_fields()\n",
    "Analysis_Article.save_allCounts_2_file(mypath)\n",
    "Analysis_Article.save_Counts_for_types(mypath)\n",
    "Analysis_Article.save_uniq_fields(mypath)\n",
    "Analysis_Article.save_dataField_Analysis(mypath)     \n",
    "log.logging('All Data Field Countings finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Articles read -> 53116\n",
      "#Articles read successfully -> 53115\n"
     ]
    }
   ],
   "source": [
    "from file_commander import my_file_commander\n",
    "from sapsik_bir_Analyser import Article_Analyser\n",
    "commander = my_file_commander()\n",
    "\n",
    "### TO READ\n",
    "article_path = log.get_output_path()+'All_Articles_Interested.txt'\n",
    "splitter_patter = '\\n\\n\\n'\n",
    "dataContains_tuples = ['id','title','infoBox_type','bulk_infoBox','clean_infoBox','bulk_paragraph']\n",
    "articles = commander.my_tub_file_reader(article_path,splitter_patter,dataContains_tuples)\n",
    "Analysis_Article = Article_Analyser(articles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'replace' BURDAAA\n",
      "'NoneType' object has no attribute 'replace' BURDAAA\n",
      "'NoneType' object has no attribute 'replace' BURDAAA\n",
      "'NoneType' object has no attribute 'replace' BURDAAA\n",
      "'NoneType' object has no attribute 'replace' BURDAAA\n",
      "'NoneType' object has no attribute 'replace' BURDAAA\n",
      "#Tried to convert to DA from infoBox 53115\n",
      "#Converted to DA from infoBox 43657\n",
      "#DA saved succesfully 101621\n",
      "#Articles saved successfully -> 53115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import DA_Combiner as Combiner\n",
    "rules = Combiner.get_rules('./RULES.txt')\n",
    "Analysis_Article.articles ,possible_DAs = Combiner.create_DA_combinations(rules,Analysis_Article.articles)\n",
    "save_path = log.get_output_path() + 'Dialog_Acts'\n",
    "tried,counter,DA_id = Combiner.save_DAs(save_path,possible_DAs)\n",
    "\n",
    "\n",
    "log.add_splitter()\n",
    "log.save_log('DA Convertion',str( '#Tried to convert to DA from infoBox -> '+str(tried) \n",
    "             + '\\n#Converted to DA from infoBox -> '+ str(counter) \n",
    "             + '\\n#DA saved succesfully -> '+ str(DA_id) ))\n",
    "\n",
    "###Save for all interested clean data\n",
    "### TO SAVE\n",
    "dataContains_tuples = ['id','title','infoBox_type','bulk_infoBox','clean_infoBox','bulk_paragraph','DA_as_str','DA_fields']\n",
    "commander.my_tub_file_recorder(log.get_output_path()+'All_Articles_Interested_V2.txt',Analysis_Article.articles,'\\n\\n\\n',dataContains_tuples)\n",
    "log.logging('#Total Articles saved successfully ( > Interested_V2 ) : '+ str(commander.saved_successfully))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import json \n",
    "from dataCleaner import process_bulk_paragraph, set_environment, clear_environment\n",
    "\n",
    "# Sample usage of dataCleaner.py\n",
    "\n",
    "set_environment() # create outputs folder to work in with temporary text files\n",
    "\n",
    "# process the bulk data\n",
    "clean_sentence_number = 0 \n",
    "for i,a in enumerate(Analysis_Article.articles):\n",
    "    clean_paragraph ,sentences, AckMessage = process_bulk_paragraph(a.article['bulk_paragraph'])\n",
    "    sentance_str = sentences[0] + '@'+sentences[1]\n",
    "    Analysis_Article.articles[i].article['clean_paragraph'] = clean_paragraph  \n",
    "    Analysis_Article.articles[i].article['clean_sentences'] = sentance_str\n",
    "    if sentences[0] != 'None':\n",
    "        clean_sentence_number +=1\n",
    "\n",
    "\n",
    "clear_environment() # clear all temporary files\n",
    "\n",
    "\n",
    "###Save for all interested clean data\n",
    "### TO SAVE\n",
    "dataContains_tuples = ['id','title','infoBox_type','bulk_infoBox','clean_infoBox','bulk_paragraph','DA_as_str','DA_fields','clean_paragraph','clean_sentences']\n",
    "commander.my_tub_file_recorder(log.get_output_path()+'All_Articles_Interested_V3.txt',Analysis_Article.articles,'\\n\\n\\n',dataContains_tuples)\n",
    "log.logging('#Total Articles saved successfully ( > Interested_V3 ) : '+ str(commander.saved_successfully))\n",
    "log.logging('#Total Articles saved with Sentence/s ( > Interested_V3 ) : '+ str(clean_sentence_number))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../<2018-12-03>Outputs-BLACK BOX CODE/\n",
      "#Articles read -> 53116\n",
      "#Articles read successfully -> 53115\n"
     ]
    }
   ],
   "source": [
    "from my_logging import my_outputs_and_logging\n",
    "\n",
    "log = my_outputs_and_logging('BLACK BOX CODE')\n",
    "\n",
    "print log.get_output_path()\n",
    "from file_commander import my_file_commander\n",
    "from sapsik_bir_Analyser import Article_Analyser\n",
    "commander = my_file_commander()\n",
    "\n",
    "### TO READ\n",
    "article_path = '../<2018-12-02>Outputs-BLACK BOX CODE/All_Articles_Interested_V3.txt'\n",
    "splitter_patter = '\\n\\n\\n'\n",
    "dataContains_tuples = ['id','title','infoBox_type','bulk_infoBox','clean_infoBox','bulk_paragraph','DA_as_str','DA_fields','clean_paragraph','clean_sentences']\n",
    "articles = commander.my_tub_file_reader(article_path,splitter_patter,dataContains_tuples)\n",
    "Analysis_Article = Article_Analyser(articles)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<file_commander.Article instance at 0x108da5ab8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Analysis_Article.articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"10\", \n",
      "    \"title\": \"Cengiz Han\", \n",
      "    \"infoBox_type\": \"Kraliyet\", \n",
      "    \"bulk_infoBox\": {\n",
      "        \"doğum_tarihi\": \"[[1162]]\", \n",
      "        \"resim_boyutu\": \"\", \n",
      "        \"tam ismi\": \"Temuçin\", \n",
      "        \"dini\": \"[[Tengricilik|Göktengricilik]]\", \n",
      "        \"sonra_gelen\": \"[[Ögeday|Ögeday Han]]\", \n",
      "        \"çocukları\": \"[[Cuci]]<br />[[Çağatay]]<br />[[Ögeday]]<br />[[Tuluy]]\", \n",
      "        \"altyazı\": \"\", \n",
      "        \"hanedan\": \"[[Börçigin]]\", \n",
      "        \"taç_giymesi\": \"\", \n",
      "        \"babası\": \"[[Yesügey]]\", \n",
      "        \"hüküm_süresi\": \"1206 – 17 Ağustos 1227\", \n",
      "        \"imza\": \"\", \n",
      "        \"doğum_yeri\": \"Dülün-Boldak, [[Moğolistan]]\", \n",
      "        \"başlık\": \"[[Han]]<br/>[[Kağan]]\", \n",
      "        \"veliaht\": \"\", \n",
      "        \"isim\": \"Cengiz Han<br />Чингис Хаан\", \n",
      "        \"ölüm_yeri\": \"\", \n",
      "        \"defin_yeri\": \"\", \n",
      "        \"veraset\": \"1. [[Moğol İmparatorluğu|Moğol İmparatorluğu Hanı]]\", \n",
      "        \"defin_tarihi\": \"\", \n",
      "        \"resim\": \"YuanEmperorAlbumGenghisPortrait.jpg\", \n",
      "        \"önce_gelen\": \"\", \n",
      "        \"annesi\": \"[[Höelin]]\", \n",
      "        \"ölüm_tarihi\": \"{{Ölüm tarihi ve yaşı|1227|8|18|1162|1|1}}\", \n",
      "        \"eşi\": \"[[Börte|Börte Ujin]] <br> Kulan <br> Yusui <br> Yusigen\"\n",
      "    }, \n",
      "    \"clean_infoBox\": {\n",
      "        \"doğumyeri\": \"Dülün-Boldak, Moğolistan\", \n",
      "        \"hanedan\": \"Börçigin\", \n",
      "        \"ad\": \"Cengiz Han, Чингис Хаан\", \n",
      "        \"babası\": \"Yesügey\", \n",
      "        \"veraset\": \"1. Moğol İmparatorluğu Hanı\", \n",
      "        \"dini\": \"Göktengricilik\", \n",
      "        \"tamismi\": \"Temuçin\", \n",
      "        \"doğumtarihi\": \"1162\", \n",
      "        \"ölümtarihi\": \"18 Ağustos 1227\", \n",
      "        \"sonragelen\": \"Ögeday Han\", \n",
      "        \"başlık\": \"Han, Kağan\", \n",
      "        \"annesi\": \"Höelin\", \n",
      "        \"eşi\": \"Börte Ujin ,  Yusui ,  Yusigen\", \n",
      "        \"hükümsüresi\": \"1206 – 17 Ağustos 1227\", \n",
      "        \"çocukları\": \"Cuci, Ögeday, Tuluy\"\n",
      "    }, \n",
      "    \"bulk_paragraph\": \"<nl>'''Cengiz Han''' (''Cenghis Khan'', ''Çinggis Haan'' ya da doğum adıyla '''Temuçin''' (anlamı: demirci), [[Moğolca]]: ''Чингис Хаан'' ya da \\\"Tengiz\\\" (anlamı: deniz), {{dil-fa|چنگیز خان}}; d. [[1162]] – ö. [[18 Ağustos]] [[1227]]), [[Moğollar|Moğol]] komutan, hükümdar ve [[Moğol İmparatorluğu]]'nun kurucusudur. Cengiz Han, 13. Yüzyılın başında [[Orta Asya]]'daki tüm göçebe bozkır kavimlerini birleştirerek bir ulus haline getirdi ve o ulusu ''Moğol'' siyasi kimliği çatısı altında topladı. Dünya tarihinin en büyük askeri dehalarından biri olarak kabul edilen Cengiz Han, hükümdarlığı döneminde 1206-1227 arasında [[Kuzey Çin]]'deki [[Batı Xia Hanedanı|Batı Xia]] ve [[Jin Hanedanlığı (1115-1234)|Jin Hanedanı]], [[Türkistan]]'daki [[Kara Hıtay]], [[Maveraünnehir]], [[Harezm]], [[Horasan]] ve [[İran]]'daki [[Harzemşahlar]] ile [[Kafkasya]]'da [[Gürcüler]], [[Deşt-i Kıpçak]]'taki [[Kiev Knezliği|Rus Knezlikleri]] ve [[Kıpçaklar]] ile [[İdil Bulgarları]] üzerine gerçekleştirilen seferler sonucunda [[Pasifik Okyanusu]]'ndan [[Hazar Denizi]]’ne ve [[Karadeniz]]'in kuzeyine kadar uzanan bir imparatorluk kurdu.<nl><nl>Bozkır geleneğinden gelen onlu teşkilatı kullanarak [[Meritokratik]] (liyâkata bağlı) bir ordu meydana getiren Cengiz Han’ın büyük bir asker olarak ün kazanmasının temelinde, kurduğu posta teşkilatı ve casus ağı ile istihbarat sanatına verdiği büyük değer önemli bir yer tutar. Seferleri sonucunda, pek çok şehir tahrip olmuş ve milyonlarca insan da katledilmişti ancak ''Cengiz Han Yasası'' adı ile metinleştirilen kurallar ile işkenceyi yasaklayıp, zanaatkarlar, doktorlar, belli bilgi becerisi olan eğitimli kişiler ve her dinden din adamlarına, hangi milletten olursa olsun aralarında bir ayrım yapılmaksızın saygı gösterilmesi ve vergiden muaf tutulmalarını kanunlaştırmıştır<ref>[http://www.payvand.com/news/03/jun/1074.html payvand.com]</ref> Cengiz Han, halkının yazıya sahip olmasını sağlamak için Uygurlardan önemli bahşıları başkenti [[Karakurum]]’a çağırmış ve Moğolca için [[Uygur alfabesi]]ni uyarlatarak bunu çocuklarına da öğretmesini istemiştir.\", \n",
      "    \"DA_as_str\": \"000003_DA_Kraliyet_IN_CAT_NUMBER.0_(Kişi Türü = 'Kraliyet' ,doğumtarihi = '1162' ,hanedan = 'Börçigin' ,ad = 'Cengiz Han, Чингис Хаан')\\n000002_DA_Kraliyet_IN_CAT_NUMBER.1_(Kişi Türü = 'Kraliyet' ,doğumtarihi = '1162' ,hanedan = 'Börçigin' ,ad = 'Cengiz Han, Чингис Хаан' ,ölümtarihi = '18 Ağustos 1227')\\n000001_DA_Kraliyet_IN_CAT_NUMBER.2_(Kişi Türü = 'Kraliyet' ,doğumtarihi = '1162' ,hükümsüresi = '1206 – 17 Ağustos 1227' ,hanedan = 'Börçigin' ,ad = 'Cengiz Han, Чингис Хаан')\\n000000_DA_Kraliyet_IN_CAT_NUMBER.3_(Kişi Türü = 'Kraliyet' ,doğumtarihi = '1162' ,hükümsüresi = '1206 – 17 Ağustos 1227' ,hanedan = 'Börçigin' ,ad = 'Cengiz Han, Чингис Хаан' ,ölümtarihi = '18 Ağustos 1227')\\n\", \n",
      "    \"DA_fields\": [\n",
      "        {\n",
      "            \"doğumtarihi\": \"1162\", \n",
      "            \"hükümsüresi\": \"1206 – 17 Ağustos 1227\", \n",
      "            \"hanedan\": \"Börçigin\", \n",
      "            \"ad\": \"Cengiz Han, Чингис Хаан\", \n",
      "            \"ölümtarihi\": \"18 Ağustos 1227\"\n",
      "        }, \n",
      "        {\n",
      "            \"doğumtarihi\": \"1162\", \n",
      "            \"hükümsüresi\": \"1206 – 17 Ağustos 1227\", \n",
      "            \"hanedan\": \"Börçigin\", \n",
      "            \"ad\": \"Cengiz Han, Чингис Хаан\"\n",
      "        }, \n",
      "        {\n",
      "            \"doğumtarihi\": \"1162\", \n",
      "            \"hanedan\": \"Börçigin\", \n",
      "            \"ad\": \"Cengiz Han, Чингис Хаан\", \n",
      "            \"ölümtarihi\": \"18 Ağustos 1227\"\n",
      "        }, \n",
      "        {\n",
      "            \"doğumtarihi\": \"1162\", \n",
      "            \"hanedan\": \"Börçigin\", \n",
      "            \"ad\": \"Cengiz Han, Чингис Хаан\"\n",
      "        }\n",
      "    ], \n",
      "    \"clean_paragraph\": \"Cengiz Han (d. 1162 – ö. 18 Ağustos 1227), Moğol komutan, hükümdar ve Moğol İmparatorluğu'nun kurucusudur. Cengiz Han, 13. Yüzyılın başında Orta Asya'daki tüm göçebe bozkır kavimlerini birleştirerek bir ulus haline getirdi ve o ulusu Moğol siyasi kimliği çatısı altında topladı. Dünya tarihinin en büyük askeri dehalarından biri olarak kabul edilen Cengiz Han, hükümdarlığı döneminde 1206-1227 arasında Kuzey Çin'deki Batı Xia ve Jin Hanedanı, Türkistan'daki Kara Hıtay, Maveraünnehir, Harezm, Horasan ve İran'daki Harzemşahlar ile Kafkasya'da Gürcüler, Deşt-i Kıpçak'taki Rus Knezlikleri ve Kıpçaklar ile İdil Bulgarları üzerine gerçekleştirilen seferler sonucunda Pasifik Okyanusu'ndan Hazar Denizi’ne ve Karadeniz'in kuzeyine kadar uzanan bir imparatorluk kurdu.\", \n",
      "    \"clean_sentences\": \"Cengiz Han (d. 1162 – ö. 18 Ağustos 1227), Moğol komutan, hükümdar ve Moğol İmparatorluğu'nun kurucusudur.@Cengiz Han, 13. Yüzyılın başında Orta Asya'daki tüm göçebe bozkır kavimlerini birleştirerek bir ulus haline getirdi ve o ulusu Moğol siyasi kimliği çatısı altında topladı.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print json.dumps(Analysis_Article.articles[0].article, ensure_ascii=False, encoding='utf8',indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_sentance(DA_field, sentence ):\n",
    "    '''\n",
    "    print '\\n\\ndenenen\\n','-'*40\n",
    "    print json.dumps(DA_field, ensure_ascii=False, encoding='utf8',indent = 4)            \n",
    "    print sentence      \n",
    "    '''\n",
    "    flag = False\n",
    "    if sentence=='None':\n",
    "        return flag\n",
    "    \n",
    "    flag = True\n",
    "    for value in DA_field.values():\n",
    "        values = value.split(' ')\n",
    "        temp_flag = False\n",
    "        for part_value in values:\n",
    "            if (part_value[:-1].encode('utf-8') in sentence):\n",
    "                temp_flag = True\n",
    "                break\n",
    "            else:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "matcher = []\n",
    "for a in Analysis_Article.articles:\n",
    "    a = a.article\n",
    "    sentence = a['clean_sentences'].split('@')[0]\n",
    "    \n",
    "    DA_fields = a['DA_fields']\n",
    "    tempList = []\n",
    "    index = -1\n",
    "    for i,DA_field in enumerate(DA_fields): \n",
    "        try:\n",
    "            if match_sentance(DA_field, sentence ):\n",
    "                match = ( a['DA_as_str'].split('\\n')[i] , sentence )\n",
    "                matcher.append(match)\n",
    "                break\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(log.get_output_path()+'matcher.txt','w')\n",
    "\n",
    "for i in matcher:\n",
    "    a =  str(i[0])+'\\n'+str(i[1]) +'\\n\\n\\n'\n",
    "    f.write(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3595"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
